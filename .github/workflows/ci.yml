name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'

jobs:
  lint:
    name: Lint Code
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install linting dependencies
        run: |
          pip install flake8 black
      
      - name: Run Black
        run: |
          black --check databricks/ airflow/ config/ utils/
      
      - name: Run flake8
        run: |
          flake8 databricks/ airflow/ config/ utils/ --max-line-length=127

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest-cov
      
      - name: Initialize Database
        run: |
          python scripts/load_data_duckdb.py
      
      - name: Run unit tests
        run: |
          pytest tests/ -v --cov=. --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: false

  databricks_deploy:
    name: Deploy to Databricks
    runs-on: ubuntu-latest
    needs: [lint, test]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Databricks CLI
        run: |
          pip install databricks-cli
      
      - name: Configure Databricks CLI
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          echo "[DEFAULT]" > ~/.databricksrc
          echo "host = $DATABRICKS_HOST" >> ~/.databricksrc
          echo "token = $DATABRICKS_TOKEN" >> ~/.databricksrc
      
      - name: Deploy notebooks
        run: |
          databricks workspace import_dir databricks/notebooks /Repos/markets-data-hub-repo/databricks/notebooks --overwrite
      
      - name: Deploy SQL models
        run: |
          databricks workspace import_dir sql/models /Repos/markets-data-hub-repo/sql/models --overwrite

  quality_gates:
    name: Data Quality Gates
    runs-on: ubuntu-latest
    needs: [test]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Great Expectations
        run: |
          pip install great-expectations duckdb
      
      - name: Validate configurations
        run: |
          python -c "import yaml; yaml.safe_load(open('data_quality/ge_rules.yaml'))"
          echo "Data quality configurations validated"
